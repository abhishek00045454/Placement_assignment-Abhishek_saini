{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations to apply to the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define the dataloaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 10\n",
    "\n",
    "# Define the first CNN architecture\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(16 * 8 * 8, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 8 * 8)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define the second CNN architecture\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(16 * 8 * 8, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 8 * 8)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define the third CNN architecture\n",
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(16 * 4 * 4, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define the fourth CNN architecture\n",
    "class Net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(32 * 8 * 8, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define the fifth CNN architecture\n",
    "class Net5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(32 * 4 * 4, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 4 * 4)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the models\n",
    "model1 = Net1().to(device)\n",
    "model2 = Net2().to(device)\n",
    "model3 = Net3().to(device)\n",
    "model4 = Net4().to(device)\n",
    "model5 = Net5().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.001)\n",
    "optimizer4 = optim.Adam(model4.parameters(), lr=0.001)\n",
    "optimizer5 = optim.Adam(model5.parameters(), lr=0.001)\n",
    "\n",
    "# Train and evaluate the models\n",
    "num_epochs = 10\n",
    "\n",
    "# Define a helper function for training\n",
    "def train_model(model, optimizer):\n",
    "    model.train()\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Define a helper function for evaluation\n",
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    accuracy = total_correct / total_samples\n",
    "    return accuracy\n",
    "\n",
    "# Training loop for Model 1\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model1, optimizer1)\n",
    "\n",
    "# Evaluate Model 1\n",
    "accuracy1 = evaluate_model(model1)\n",
    "print(f\"Accuracy for Model 1: {accuracy1 * 100:.2f}%\")\n",
    "\n",
    "# Training loop for Model 2\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model2, optimizer2)\n",
    "\n",
    "# Evaluate Model 2\n",
    "accuracy2 = evaluate_model(model2)\n",
    "print(f\"Accuracy for Model 2: {accuracy2 * 100:.2f}%\")\n",
    "\n",
    "# Training loop for Model 3\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model3, optimizer3)\n",
    "\n",
    "# Evaluate Model 3\n",
    "accuracy3 = evaluate_model(model3)\n",
    "print(f\"Accuracy for Model 3: {accuracy3 * 100:.2f}%\")\n",
    "\n",
    "# Training loop for Model 4\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model4, optimizer4)\n",
    "\n",
    "# Evaluate Model 4\n",
    "accuracy4 = evaluate_model(model4)\n",
    "print(f\"Accuracy for Model 4: {accuracy4 * 100:.2f}%\")\n",
    "\n",
    "# Training loop for Model 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model5, optimizer5)\n",
    "\n",
    "# Evaluate Model 5\n",
    "accuracy5 = evaluate_model(model5)\n",
    "print(f\"Accuracy for Model 5: {accuracy5 * 100:.2f}%\")\n",
    "\n",
    "# Create a comparison table\n",
    "table = {\n",
    "    \"Architecture\": [\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\", \"Model 5\"],\n",
    "    \"Parameters\": [sum(p.numel() for p in model1.parameters()), \n",
    "                   sum(p.numel() for p in model2.parameters()), \n",
    "                   sum(p.numel() for p in model3.parameters()), \n",
    "                   sum(p.numel() for p in model4.parameters()), \n",
    "                   sum(p.numel() for p in model5.parameters())],\n",
    "    \"Accuracy\": [accuracy1 * 100, accuracy2 * 100, accuracy3 * 100, accuracy4 * 100, accuracy5 * 100]\n",
    "}\n",
    "\n",
    "# Print the comparison table\n",
    "print(\"\\nComparison Table:\")\n",
    "print(\"--------------\")\n",
    "print(\"{:<12} {:<12} {:<12}\".format(\"Architecture\", \"Parameters\", \"Accuracy\"))\n",
    "print(\"--------------\")\n",
    "for i in range(len(table[\"Architecture\"])):\n",
    "    print(\"{:<12} {:<12} {:.2f}%\".format(table[\"Architecture\"][i], table[\"Parameters\"][i], table[\"Accuracy\"][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
